# utils/OCR.py
# ============================================
# í™”ì¥í’ˆ OCR ë¶„ì„ ëª¨ë“ˆ (MariaDB + SQLAlchemy ë²„ì „)
# [ìˆ˜ì •] FTS ê²€ìƒ‰ ë¡œì§ì„ 'Top-K' + 'difflib.SequenceMatcher'ë¡œ ë³€ê²½
# ============================================

import os
import io
import re
import difflib  # <-- [ì‹ ê·œ] ë¬¸ìì—´ ìœ ì‚¬ë„ ë¹„êµ ë¼ì´ë¸ŒëŸ¬ë¦¬ import
from typing import Dict, List, Optional, Any
from dotenv import load_dotenv, find_dotenv
from google.cloud import vision
from PIL import Image
from sqlalchemy import create_engine, text
from sqlalchemy.engine import Engine
from urllib.parse import quote_plus

# ============================================
# ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° (ìˆ˜ì • ì—†ìŒ)
# ============================================

def get_engine() -> Engine:
    """í™˜ê²½ ë³€ìˆ˜ì—ì„œ DB ì •ë³´ë¥¼ ì½ì–´ SQLAlchemy ì—”ì§„ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    load_dotenv()
    
    dialect = os.getenv("DB_DIALECT", "{DB_DIALECT}")
    host    = os.getenv("DB_HOST", "{DB_HOST}")
    port    = os.getenv("DB_PORT", "{DB_PORT}")
    user    = os.getenv("DB_USER", "{DB_USER}")
    pw      = os.getenv("DB_PASSWORD", "{DB_PASSWORD}")
    name    = os.getenv("DB_NAME", "{DB_NAME}")
    
    dsn = f"{dialect}://{quote_plus(user)}:{quote_plus(pw)}@{host}:{port}/{quote_plus(name)}?charset=utf8mb4"
    return create_engine(dsn, pool_pre_ping=True, future=True)

# ============================================
# OCR ë° ê²€ì¦ í•¨ìˆ˜ (ìˆ˜ì • ì—†ìŒ)
# ============================================

def extract_text_from_image(image_path: str) -> Optional[str]:
    """[ìˆ˜ì •] Google Cloud Vision API ì¸ì¦ì„ 'ì ˆëŒ€ ê²½ë¡œ'ë¡œ ìˆ˜ì •"""
    try:
        dotenv_path = find_dotenv()
        if not dotenv_path:
            raise Exception("'.env' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (find_dotenv() ì‹¤íŒ¨)")
        load_dotenv(dotenv_path) 
        base_dir = os.path.dirname(dotenv_path)
        json_filename = os.getenv("GOOGLE_APPLICATION_CREDENTIALS")
        if not json_filename:
            raise Exception("'.env' íŒŒì¼ì— GOOGLE_APPLICATION_CREDENTIALSê°€ ì—†ìŠµë‹ˆë‹¤.")
        abs_json_path = os.path.join(base_dir, json_filename)
        client = vision.ImageAnnotatorClient.from_service_account_json(abs_json_path)
        if not os.path.exists(abs_json_path):
            raise Exception(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (ê²½ë¡œ í™•ì¸): {abs_json_path}")
            
        with io.open(image_path, 'rb') as image_file:
            content = image_file.read()
        image = vision.Image(content=content)
        response = client.document_text_detection(image=image)
        if response.error.message:
            raise Exception(f"API ì˜¤ë¥˜: {response.error.message}")
        return response.full_text_annotation.text
    except Exception as e:
        print(f"OCR ì¶”ì¶œ ì˜¤ë¥˜: {e}") 
        return None

def validate_cosmetic_image(ocr_text: str) -> Dict[str, Any]:
    """OCR í…ìŠ¤íŠ¸ë¡œ í™”ì¥í’ˆ ì´ë¯¸ì§€ ì—¬ë¶€ë¥¼ íŒë³„í•©ë‹ˆë‹¤."""
    if not ocr_text or len(ocr_text.strip()) < 10:
        return {
            'is_valid': False,
            'has_text': False,
            'error_message': 'í…ìŠ¤íŠ¸ê°€ ì—†ëŠ” ì‚¬ì§„ì…ë‹ˆë‹¤.',
            'match_count': 0
        }
    
    cosmetic_keywords = [
        'í™”ì¥í’ˆ', 'í¬ë¦¼', 'ë¡œì…˜', 'ì—ì„¼ìŠ¤', 'ì„¸ëŸ¼', 'í† ë„ˆ', 'ìŠ¤í‚¨',
        'ì—ë©€ì „', 'í´ë Œì§•', 'ë§ˆìŠ¤í¬', 'íŒ©', 'ì„ í¬ë¦¼', 'íŒŒìš´ë°ì´ì…˜',
        'ì¿ ì…˜', 'ë¦½ìŠ¤í‹±', 'ìƒ´í‘¸', 'ë¦°ìŠ¤', 'ë°”ë””', 'í–¥ìˆ˜',
        'ìš©ëŸ‰', 'ml', 'g', 'ì„±ë¶„', 'ì‚¬ìš©ë²•', 'ì œì¡°', 'ìœ í†µê¸°í•œ',
        'í™”ì¥í’ˆì œì¡°ì—…ì', 'í™”ì¥í’ˆì±…ì„íŒë§¤ì—…ì', 'ì‹ì•½ì²˜',
        'ì „ì„±ë¶„', 'ingredients'
    ]
    
    match_count = sum(1 for keyword in cosmetic_keywords if keyword.lower() in ocr_text.lower())
    
    is_valid = match_count >= 1
    
    return {
        'is_valid': is_valid,
        'has_text': True,
        'match_count': match_count,
        'error_message': None if is_valid else 'í™”ì¥í’ˆ ì‚¬ì§„ì´ ì•„ë‹™ë‹ˆë‹¤.'
    }

# ============================================
# í™”ì¥í’ˆ ë¶„ì„ê¸° í´ë˜ìŠ¤
# ============================================

class CosmeticAnalyzer:
    """í™”ì¥í’ˆ ë°ì´í„° ë¶„ì„ ë° ì£¼ì˜ ì„±ë¶„ ì¡°íšŒë¥¼ ë‹´ë‹¹í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.engine = get_engine()
    
    def analyze_from_text(self, ocr_text: str) -> Optional[Dict[str, Any]]:
        """
        [ìˆ˜ì •] FTS ê²€ìƒ‰ ë¡œì§ì„ 'Top-K í›„ë³´ ê²€ì¦' ë°©ì‹ìœ¼ë¡œ ë³€ê²½
        """
        # 1. ê²€ì¦
        validation = validate_cosmetic_image(ocr_text)
        if not validation['is_valid']:
            pass
        
        # 2. ì œí’ˆëª… í›„ë³´ ì¶”ì¶œ (ìƒìœ„ 10ì¤„ + ë¶ˆìš©ì–´ í•„í„°ë§)
        lines = [line.strip() for line in ocr_text.splitlines() if line.strip()]
        product_candidates = []
        STOP_KEYWORDS = ['ì‚¬ìš©', 'íŒí”„', 'ê³µê¸°', 'ë¶„ë¦¬ë°°ì¶œ', 'í”Œë¼ìŠ¤í‹±', 'ì „ì„±ë¶„', 'ì£¼ì˜', 'ì œì¡°', 'ìš©ëŸ‰', 'ml', 'ë°©ë²•', 'í”¼ë¶€', 'ê³ ë¯¼']

        for line in lines[:10]:
            if len(line) < 3 or len(line) > 60: 
                continue
            if any(keyword in line for keyword in STOP_KEYWORDS):
                continue
            if len(re.findall(r'[ê°€-í£a-zA-Z]', line)) > len(line) * 0.5:
                product_candidates.append(line)
        
        # 3. [ìˆ˜ì •] DBì—ì„œ ì œí’ˆ ê²€ìƒ‰ (FTS ìš°ì„ , LIKE ì°¨ì„ )
        product_data = None
        
        # 3-1. FTS
        clean_search_text = " ".join(product_candidates) 
        print(f"[DEBUG] FTS Search Text: '{clean_search_text}'") 
        
        if clean_search_text:
             # [ìˆ˜ì •] Top-K ë¡œì§ì€ 'clean_search_text'ë§Œ ì‚¬ìš©
             product_data = self._fuzzy_search_product(clean_search_text)
        
        # 3-2. FTS ì‹¤íŒ¨ ì‹œ, LIKE
        if not product_data:
            print("[DEBUG] FTS Failed. Falling back to LIKE search...") 
            for candidate in product_candidates:
                product_data = self._search_product_by_name(candidate, use_fts=False) 
                if product_data:
                    break 
        
        # 4. DB ì¡°íšŒ ìµœì¢… ì‹¤íŒ¨ ì‹œ, OCR í…ìŠ¤íŠ¸ ì§ì ‘ ë¶„ì„ (ê¸°ì¡´ê³¼ ë™ì¼)
        if not product_data:
            ocr_ingredients = self._extract_ingredients_from_ocr(ocr_text)
            caution_ingredients = self._query_caution_ingredients(ocr_ingredients)
            
            return {
                'source': 'ocr_direct_analysis',
                'product_name': None,
                'brand': None,
                'price_krw': None,
                'capacity': None,
                'image_url': None,
                'ingredients': ocr_ingredients,
                'caution_ingredients': caution_ingredients,
                'ocr_text': ocr_text,
                'validation': validation,
                'error': 'ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì œí’ˆì„ ì°¾ì§€ ëª»í•´ OCR í…ìŠ¤íŠ¸ë¡œ ì„±ë¶„ë§Œ ë¶„ì„í•©ë‹ˆë‹¤.'
            }
        
        # 5. DB ì¡°íšŒ ì„±ê³µ ì‹œ ì£¼ì˜ ì„±ë¶„ ì¡°íšŒ (ê¸°ì¡´ê³¼ ë™ì¼)
        caution_ingredients = self._query_caution_ingredients(product_data.get('ingredients', []))
        
        # 6. ê²°ê³¼ ë°˜í™˜ (ê¸°ì¡´ê³¼ ë™ì¼)
        return {
            'source': 'database',
            'product_name': product_data.get('product_name'),
            'brand': product_data.get('brand'),
            'price_krw': product_data.get('price_krw'),
            'capacity': product_data.get('capacity'),
            'image_url': product_data.get('image_url'),
            'ingredients': product_data.get('ingredients', []),
            'caution_ingredients': caution_ingredients,
            'ocr_text': ocr_text,
            'validation': validation
        }

    def _extract_ingredients_from_ocr(self, ocr_text: str) -> List[str]:
        """OCR í…ìŠ¤íŠ¸ì—ì„œ 'ì „ì„±ë¶„' ì´í›„ì˜ í…ìŠ¤íŠ¸ë¥¼ íŒŒì‹±í•©ë‹ˆë‹¤."""
        try:
            match = re.search(r'ì „ì„±ë¶„|ingredients', ocr_text, re.IGNORECASE)
            
            if match:
                ingredients_str = ocr_text[match.end():].strip(': \n')
            else:
                ingredients_str = ocr_text

            all_ingredients = [
                ing.strip() 
                for ing in re.split(r'[,/\n]', ingredients_str) 
                if ing.strip() and len(ing.strip()) > 1
            ]
            return all_ingredients
        except Exception:
            return []

    def analyze_from_product_name(self, product_name: str) -> Optional[Dict[str, Any]]:
        """
        ì œí’ˆëª…ìœ¼ë¡œ ì§ì ‘ ê²€ìƒ‰í•˜ì—¬ ë¶„ì„í•©ë‹ˆë‹¤. (ì±„íŒ… UIì˜ 'ê²€ìƒ‰' ë²„íŠ¼ìš©)
        """
        product_data = self._search_product_by_name(product_name, use_fts=True)
        if not product_data:
            return None
        caution_ingredients = self._query_caution_ingredients(product_data.get('ingredients', []))
        return {
            'source': 'database',
            'product_name': product_data.get('product_name'),
            'brand': product_data.get('brand'),
            'price_krw': product_data.get('price_krw'),
            'capacity': product_data.get('capacity'),
            'image_url': product_data.get('image_url'),
            'ingredients': product_data.get('ingredients', []),
            'caution_ingredients': caution_ingredients,
            'ocr_text': None,
            'validation': {'is_valid': True, 'has_text': True, 'match_count': 0}
        }
    
    def _search_product_by_name(self, product_name: str, use_fts: bool = True) -> Optional[Dict[str, Any]]:
        """[ìˆ˜ì •] ì œí’ˆëª…ìœ¼ë¡œ DBë¥¼ ê²€ìƒ‰ (FTS ë˜ëŠ” LIKE)"""
        try:
            with self.engine.connect() as conn:
                result = None
                if use_fts:
                    query_fts = text("""
                        SELECT 
                            product_name, brand, image_url, price_krw, capacity, ingredients,
                            MATCH(product_name) AGAINST(:name IN NATURAL LANGUAGE MODE) as relevance_score
                        FROM product_data 
                        WHERE MATCH(product_name) AGAINST(:name IN NATURAL LANGUAGE MODE)
                        ORDER BY relevance_score DESC
                        LIMIT 1
                    """)
                    result_fts = conn.execute(query_fts, {"name": product_name}).fetchone()
                    if result_fts and result_fts[6] > 0.5:
                        result = result_fts
                if not result:
                    query_like = text("""
                        SELECT product_name, brand, image_url, price_krw, capacity, ingredients
                        FROM product_data
                        WHERE product_name LIKE :name
                        LIMIT 1
                    """)
                    result_like = conn.execute(query_like, {"name": f"%{product_name}%"}).fetchone()
                    result = result_like
                if result:
                    return {
                        'product_name': result[0],
                        'brand': result[1],
                        'image_url': result[2],
                        'price_krw': result[3],
                        'capacity': result[4],
                        'ingredients': result[5].split(',') if result[5] else []
                    }
                return None
        except Exception as e:
            print(f"DB ê²€ìƒ‰ ì˜¤ë¥˜ (_search_product_by_name): {e}")
            return None
    
    def _fuzzy_search_product(self, clean_search_text: str) -> Optional[Dict[str, Any]]:
        """
        [ìˆ˜ì •] FTS Top-K (K=5) + difflib.SequenceMatcher ë¡œì§
        """
        try:
            with self.engine.connect() as conn:
                # 1. FTS LIMIT 5ë¡œ ë³€ê²½
                query = text("""
                    SELECT 
                        product_name, brand, image_url, price_krw, capacity, ingredients,
                        MATCH(product_name) AGAINST(:text IN NATURAL LANGUAGE MODE) as relevance_score
                    FROM product_data
                    WHERE MATCH(product_name) AGAINST(:text IN NATURAL LANGUAGE MODE)
                    ORDER BY relevance_score DESC
                    LIMIT 5 
                """)
                
                results = conn.execute(query, {"text": clean_search_text}).fetchall()
                
                if not results:
                    return None

                # [ìˆ˜ì •] 'ê¹¨ë—í•œ ê²€ìƒ‰ì–´'ë¥¼ ë¹„êµ ê¸°ì¤€ìœ¼ë¡œ ì‚¬ìš©
                search_text_lower = clean_search_text.lower()
                best_match = None
                best_ratio = 0.0

                # 2. [ì‹ ê·œ] 5ê°œì˜ í›„ë³´ë¥¼ ëª¨ë‘ ë°˜ë³µí•˜ë©° ìµœê³ ì˜ 'ìœ ì‚¬ë„'ë¥¼ ì°¾ìŒ
                for row in results:
                    product_name_lower = row[0].lower() # DB ì œí’ˆëª…
                    
                    # [ìˆ˜ì •] SequenceMatcherë¡œ ë¬¸ìì—´ ìœ ì‚¬ë„ ê³„ì‚°
                    s = difflib.SequenceMatcher(None, search_text_lower, product_name_lower)
                    match_ratio = s.ratio()
                    
                    if match_ratio > best_ratio:
                        best_ratio = match_ratio
                        best_match = row
                
                # 3. [ìˆ˜ì •] ìµœê³ ì˜ 'ìœ ì‚¬ë„'ê°€ 60% ì´ìƒì¼ ë•Œë§Œ í†µê³¼
                if best_match and best_ratio >= 0.6: 
                    print(f"[DEBUG] FTS Best Match Found (SimRatio: {best_ratio:.0%})")
                    return {
                        'product_name': best_match[0],
                        'brand': best_match[1],
                        'image_url': best_match[2],
                        'price_krw': best_match[3],
                        'capacity': best_match[4],
                        'ingredients': best_match[5].split(',') if best_match[5] else []
                    }
                else:
                    print(f"[DEBUG] FTS Failed (Best SimRatio {best_ratio:.0%} < 60%)")
                    return None

        except Exception as e:
            print(f"í¼ì§€ ê²€ìƒ‰ ì˜¤ë¥˜ (_fuzzy_search_product): {e}")
            return None
    
    def _query_caution_ingredients(self, ingredients: List[str]) -> Dict[str, List[Dict[str, Any]]]:
        """
        [ìˆ˜ì •]
        1. ML í…Œì´ë¸”ëª…: ML_caution_ingredients
        2. ML í…Œì´ë¸” ì»¬ëŸ¼: korean_name, caution_grade, description
        """
        if not ingredients:
            return {'official': [], 'ml_predicted': []}
        
        try:
            with self.engine.connect() as conn:
                # 1. íŒŒë¼ë¯¸í„° ì¤€ë¹„
                placeholders = ','.join([':ing' + str(i) for i in range(len(ingredients))])
                params = {f'ing{i}': ing.strip() for i, ing in enumerate(ingredients)}
                
                # 2. ê³µì‹ ì£¼ì˜ ì„±ë¶„ ì¡°íšŒ
                official_query = text(f"""
                    SELECT 
                        korean_name,
                        caution_grade,
                        description
                    FROM caution_ingredients
                    WHERE korean_name IN ({placeholders})
                """)
                
                official_results = conn.execute(official_query, params).fetchall()
                official_list = [
                    {
                        'korean_name': row[0],
                        'caution_grade': row[1],
                        'description': row[2]
                    }
                    for row in official_results
                ]
                
                # 3. ML ì˜ˆì¸¡ ì£¼ì˜ ì„±ë¶„ ì¡°íšŒ (ê³µì‹ì— ì—†ëŠ” ê²ƒë§Œ)
                official_names = {item['korean_name'] for item in official_list}
                remaining_ingredients = [ing for ing in ingredients if ing not in official_names]
                
                ml_list = []
                if remaining_ingredients:
                    # 4. ë‚¨ì€ ì„±ë¶„ìš© íŒŒë¼ë¯¸í„° ì¤€ë¹„
                    ml_placeholders = ','.join([':rem' + str(i) for i in range(len(remaining_ingredients))])
                    ml_params = {f'rem{i}': ing.strip() for i, ing in enumerate(remaining_ingredients)}

                    # [ìˆ˜ì •] í…Œì´ë¸”ëª…ê³¼ ì»¬ëŸ¼ëª… ë³€ê²½
                    ml_query = text(f"""
                        SELECT 
                            korean_name,
                            caution_grade,
                            description
                        FROM ML_caution_ingredients 
                        WHERE korean_name IN ({ml_placeholders})
                    """)
                    
                    try:
                        ml_results = conn.execute(ml_query, ml_params).fetchall()
                        ml_list = [
                            {
                                'korean_name': row[0],
                                'caution_grade': row[1],
                                'description': row[2]
                            }
                            for row in ml_results
                        ]
                    except Exception as e:
                        print(f"ML ì£¼ì˜ ì„±ë¶„ ì¡°íšŒ ì˜¤ë¥˜ (ML_caution_ingredients): {e}")
                        ml_list = [] 
                
                return {
                    'official': official_list,
                    'ml_predicted': ml_list
                }
        except Exception as e:
            print(f"ì£¼ì˜ ì„±ë¶„ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return {'official': [], 'ml_predicted': []}

# ============================================
# ë©”ì¸ ì²˜ë¦¬ í•¨ìˆ˜ (ìˆ˜ì • ì—†ìŒ)
# ============================================

def process_cosmetic_image(image_path: str) -> Dict[str, Any]:
    """
    í™”ì¥í’ˆ ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•˜ê³  ë¶„ì„ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    ocr_text = extract_text_from_image(image_path)
    
    if not ocr_text:
        return {
            'success': False,
            'error': 'OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨',
            'data': None
        }
    
    analyzer = CosmeticAnalyzer()
    result = analyzer.analyze_from_text(ocr_text)
    
    if result:
        return {
            'success': True,
            'error': None,
            'data': result
        }
    else:
        return {
            'success': False,
            'error': 'í™”ì¥í’ˆ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.',
            'data': None
        }

def search_product_by_name(product_name: str) -> Dict[str, Any]:
    """
    ì œí’ˆëª…ìœ¼ë¡œ ì§ì ‘ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    """
    analyzer = CosmeticAnalyzer()
    result = analyzer.analyze_from_product_name(product_name)
    
    if result:
        return {
            'success': True,
            'error': None,
            'data': result
        }
    else:
        return {
            'success': False,
            'error': 'ì œí’ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.',
            'data': None
        }

def format_analysis_for_chat(analysis_result: Dict[str, Any]) -> Dict[str, Any]:
    """
    [ìˆ˜ì •] ML ì˜ˆì¸¡ ì„±ë¶„ í¬ë§¤íŒ… ë¡œì§ ìˆ˜ì •
    """
    if not analysis_result.get('success'):
        return {
            'text': f"âŒ {analysis_result.get('error', 'ë¶„ì„ ì‹¤íŒ¨')}",
            'image_url': None
        }
    
    data = analysis_result.get('data', {})
    
    output = []
    output.append("## ğŸ§´ í™”ì¥í’ˆ ë¶„ì„ ê²°ê³¼\n")
    
    # ì œí’ˆ ì •ë³´
    if data.get('source') == 'database':
        output.append(f"**ì œí’ˆëª…**: {data.get('product_name', 'N/A')}")
        if data.get('brand'):
            output.append(f"**ë¸Œëœë“œ**: {data['brand']}")
        if data.get('price_krw'):
            output.append(f"**ê°€ê²©**: {data['price_krw']:,}ì›")
        if data.get('capacity'):
            output.append(f"**ìš©ëŸ‰**: {data['capacity']}")
    elif data.get('source') == 'ocr_direct_analysis':
        output.append("â„¹ï¸ DBì—ì„œ ì œí’ˆì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        output.append(f"{data.get('error', 'OCR í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì„±ë¶„ë§Œ ë¶„ì„í•©ë‹ˆë‹¤.')}\n")

    output.append("")
    
    # ì£¼ì˜ ì„±ë¶„
    caution = data.get('caution_ingredients', {})
    official = caution.get('official', [])
    ml_predicted = caution.get('ml_predicted', [])
    
    # 1ì°¨: ê³µì‹ ì£¼ì˜ ì„±ë¶„
    if official:
        output.append(f"### âš ï¸ ì£¼ì˜ ì„±ë¶„ ({len(official)}ê°œ)")
        output.append("\n**ê³µì‹ ì£¼ì˜ ì„±ë¶„:**")
        for ing in official:
            grade = ing.get('caution_grade', 'N/A')
            name = ing.get('korean_name', 'N/A')
            desc = ing.get('description', '')
            output.append(f"- **{name}** (ë“±ê¸‰: {grade})")
            if desc:
                output.append(f"  {desc}")
        output.append("")
    
    # ê³µì‹/ML ëª¨ë‘ ì—†ì„ ë•Œ
    if not official and not ml_predicted:
        output.append("### âœ… ì£¼ì˜ ì„±ë¶„ ì—†ìŒ")
        output.append("ì´ ì œí’ˆì—ëŠ” ê³µì‹ ë“±ë¡ëœ ì£¼ì˜ ì„±ë¶„ì´ë‚˜ AI ì˜ˆì¸¡ ìœ í•´ ì„±ë¶„ì´ ì—†ìŠµë‹ˆë‹¤.\n")
    # ê³µì‹ì€ ì—†ì§€ë§Œ MLì€ ìˆì„ ë•Œ
    elif not official and ml_predicted:
        output.append("### âœ… ê³µì‹ ì£¼ì˜ ì„±ë¶„ ì—†ìŒ")
        output.append("ì´ ì œí’ˆì—ëŠ” ê³µì‹ ë“±ë¡ëœ ì£¼ì˜ ì„±ë¶„ì´ ì—†ìŠµë‹ˆë‹¤.\n")
    
    # 2ì°¨: ML ì˜ˆì¸¡ ì£¼ì˜ ì„±ë¶„ (ì¶”ê°€ ì •ë³´)
    if ml_predicted:
        output.append(f"### ğŸ“Š ì¶”ê°€ë¡œ ì•Œì•„ë‘ë©´ ì¢‹ì„ ì„±ë¶„ (AI ì˜ˆì¸¡) ({len(ml_predicted)}ê°œ)")
        output.append("*ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ë¡œ ì˜ˆì¸¡ëœ ë¹„ì•ˆì „ ì„±ë¶„ì…ë‹ˆë‹¤.*\n")
        for ing in ml_predicted:
            name = ing.get('korean_name', 'N/A')
            grade = ing.get('caution_grade', 'N/A')
            desc = ing.get('description', '')
            output.append(f"- **{name}** (ì˜ˆì¸¡ ë“±ê¸‰: {grade})")
            if desc:
                output.append(f"  {desc}")
    
    return {
        'text': "\n".join(output),
        'image_url': data.get('image_url')
    }