# feature/OCR.py
# ============================================
# í™”ì¥í’ˆ OCR ë¶„ì„ ëª¨ë“ˆ (MariaDB + SQLAlchemy ë²„ì „)
# [ìˆ˜ì •]
# 1. ì œí’ˆ ê²€ìƒ‰ ë¡œì§ì„ FTS -> LIKE 2ë‹¨ê³„ë¡œ ê°•í™”
# 2. ML í…Œì´ë¸”ëª…ì„ 'ML_caution_ingredients'ë¡œ ìˆ˜ì •
# 3. ML í…Œì´ë¸” ì»¬ëŸ¼ì„ 'caution_grade', 'description'ìœ¼ë¡œ ìˆ˜ì •
# ============================================

import os
import io
import re
from typing import Dict, List, Optional, Any
from dotenv import load_dotenv
from google.cloud import vision
from PIL import Image
from sqlalchemy import create_engine, text
from sqlalchemy.engine import Engine
from urllib.parse import quote_plus

# ============================================
# ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° (ìˆ˜ì • ì—†ìŒ)
# ============================================

def get_engine() -> Engine:
    """í™˜ê²½ ë³€ìˆ˜ì—ì„œ DB ì •ë³´ë¥¼ ì½ì–´ SQLAlchemy ì—”ì§„ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    load_dotenv()
    
    dialect = os.getenv("DB_DIALECT", "{DB_DIALECT}")
    host    = os.getenv("DB_HOST", "{DB_HOST}")
    port    = os.getenv("DB_PORT", "{DB_PORT}")
    user    = os.getenv("DB_USER", "{DB_USER}")
    pw      = os.getenv("DB_PASSWORD", "{DB_PASSWORD}")
    name    = os.getenv("DB_NAME", "{DB_NAME}")
    
    dsn = f"{dialect}://{quote_plus(user)}:{quote_plus(pw)}@{host}:{port}/{quote_plus(name)}?charset=utf8mb4"
    return create_engine(dsn, pool_pre_ping=True, future=True)

# ============================================
# OCR ë° ê²€ì¦ í•¨ìˆ˜ (ìˆ˜ì • ì—†ìŒ)
# ============================================

def extract_text_from_image(image_path: str) -> Optional[str]:
    """Google Cloud Vision APIë¥¼ ì‚¬ìš©í•´ ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    try:
        load_dotenv()
        client = vision.ImageAnnotatorClient()
        
        with io.open(image_path, 'rb') as image_file:
            content = image_file.read()
        
        image = vision.Image(content=content)
        response = client.document_text_detection(image=image)
        
        if response.error.message:
            raise Exception(f"API ì˜¤ë¥˜: {response.error.message}")
        
        return response.full_text_annotation.text
    except Exception as e:
        print(f"OCR ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        return None

def validate_cosmetic_image(ocr_text: str) -> Dict[str, Any]:
    """OCR í…ìŠ¤íŠ¸ë¡œ í™”ì¥í’ˆ ì´ë¯¸ì§€ ì—¬ë¶€ë¥¼ íŒë³„í•©ë‹ˆë‹¤."""
    if not ocr_text or len(ocr_text.strip()) < 10:
        return {
            'is_valid': False,
            'has_text': False,
            'error_message': 'í…ìŠ¤íŠ¸ê°€ ì—†ëŠ” ì‚¬ì§„ì…ë‹ˆë‹¤.',
            'match_count': 0
        }
    
    cosmetic_keywords = [
        'í™”ì¥í’ˆ', 'í¬ë¦¼', 'ë¡œì…˜', 'ì—ì„¼ìŠ¤', 'ì„¸ëŸ¼', 'í† ë„ˆ', 'ìŠ¤í‚¨',
        'ì—ë©€ì „', 'í´ë Œì§•', 'ë§ˆìŠ¤í¬', 'íŒ©', 'ì„ í¬ë¦¼', 'íŒŒìš´ë°ì´ì…˜',
        'ì¿ ì…˜', 'ë¦½ìŠ¤í‹±', 'ìƒ´í‘¸', 'ë¦°ìŠ¤', 'ë°”ë””', 'í–¥ìˆ˜',
        'ìš©ëŸ‰', 'ml', 'g', 'ì„±ë¶„', 'ì‚¬ìš©ë²•', 'ì œì¡°', 'ìœ í†µê¸°í•œ',
        'í™”ì¥í’ˆì œì¡°ì—…ì', 'í™”ì¥í’ˆì±…ì„íŒë§¤ì—…ì', 'ì‹ì•½ì²˜',
        'ì „ì„±ë¶„', 'ingredients'
    ]
    
    match_count = sum(1 for keyword in cosmetic_keywords if keyword.lower() in ocr_text.lower())
    
    is_valid = match_count >= 1
    
    return {
        'is_valid': is_valid,
        'has_text': True,
        'match_count': match_count,
        'error_message': None if is_valid else 'í™”ì¥í’ˆ ì‚¬ì§„ì´ ì•„ë‹™ë‹ˆë‹¤.'
    }

# ============================================
# í™”ì¥í’ˆ ë¶„ì„ê¸° í´ë˜ìŠ¤
# ============================================

class CosmeticAnalyzer:
    """í™”ì¥í’ˆ ë°ì´í„° ë¶„ì„ ë° ì£¼ì˜ ì„±ë¶„ ì¡°íšŒë¥¼ ë‹´ë‹¹í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.engine = get_engine()
    
    def analyze_from_text(self, ocr_text: str) -> Optional[Dict[str, Any]]:
        """
        [ìˆ˜ì •] OCR í…ìŠ¤íŠ¸ ê¸°ë°˜ìœ¼ë¡œ DB ê²€ìƒ‰ (FTS ìš°ì„ , LIKE ì°¨ì„ )
        """
        # 1. ê²€ì¦
        validation = validate_cosmetic_image(ocr_text)
        if not validation['is_valid']:
            # ìœ íš¨í•˜ì§€ ì•Šì•„ë„, DBì—ì„œ ëª» ì°¾ìœ¼ë©´ OCR ì§ì ‘ ë¶„ì„ì„ ì‹œë„
            pass
        
        # 2. ì œí’ˆëª… í›„ë³´ ì¶”ì¶œ (ìƒìœ„ 5ì¤„)
        lines = [line.strip() for line in ocr_text.split('\n') if line.strip()]
        product_candidates = []
        for line in lines[:5]:
            if len(line) > 3 and len(re.findall(r'[ê°€-í£a-zA-Z]', line)) > len(line) * 0.5:
                product_candidates.append(line)
        
        # 3. [ìˆ˜ì •] DBì—ì„œ ì œí’ˆ ê²€ìƒ‰ (FTS ìš°ì„ , LIKE ì°¨ì„ )
        product_data = None
        
        # 3-1. FTS (ì „ì²´ í…ìŠ¤íŠ¸, OCR_streamlit.py ë°©ì‹)
        product_data = self._fuzzy_search_product(ocr_text)
        
        # 3-2. FTS ì‹¤íŒ¨ ì‹œ, LIKE (ìƒìœ„ í›„ë³´, OCR.py ì›ë³¸ ë°©ì‹)
        if not product_data:
            for candidate in product_candidates:
                product_data = self._search_product_by_name(candidate, use_fts=False) # LIKE ê²€ìƒ‰ ì‚¬ìš©
                if product_data:
                    break # ì°¾ìœ¼ë©´ ì¤‘ë‹¨
        
        # 4. [ìˆ˜ì •] DB ì¡°íšŒ ìµœì¢… ì‹¤íŒ¨ ì‹œ, OCR í…ìŠ¤íŠ¸ ì§ì ‘ ë¶„ì„
        if not product_data:
            ocr_ingredients = self._extract_ingredients_from_ocr(ocr_text)
            caution_ingredients = self._query_caution_ingredients(ocr_ingredients)
            
            return {
                'source': 'ocr_direct_analysis',
                'product_name': None,
                'brand': None,
                'price_krw': None,
                'capacity': None,
                'image_url': None,
                'ingredients': ocr_ingredients,
                'caution_ingredients': caution_ingredients,
                'ocr_text': ocr_text,
                'validation': validation,
                'error': 'ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì œí’ˆì„ ì°¾ì§€ ëª»í•´ OCR í…ìŠ¤íŠ¸ë¡œ ì„±ë¶„ë§Œ ë¶„ì„í•©ë‹ˆë‹¤.'
            }
        
        # 5. DB ì¡°íšŒ ì„±ê³µ ì‹œ ì£¼ì˜ ì„±ë¶„ ì¡°íšŒ
        caution_ingredients = self._query_caution_ingredients(product_data.get('ingredients', []))
        
        # 6. ê²°ê³¼ ë°˜í™˜
        return {
            'source': 'database',
            'product_name': product_data.get('product_name'),
            'brand': product_data.get('brand'),
            'price_krw': product_data.get('price_krw'),
            'capacity': product_data.get('capacity'),
            'image_url': product_data.get('image_url'),
            'ingredients': product_data.get('ingredients', []),
            'caution_ingredients': caution_ingredients,
            'ocr_text': ocr_text,
            'validation': validation
        }

    def _extract_ingredients_from_ocr(self, ocr_text: str) -> List[str]:
        """OCR í…ìŠ¤íŠ¸ì—ì„œ 'ì „ì„±ë¶„' ì´í›„ì˜ í…ìŠ¤íŠ¸ë¥¼ íŒŒì‹±í•©ë‹ˆë‹¤."""
        try:
            match = re.search(r'ì „ì„±ë¶„|ingredients', ocr_text, re.IGNORECASE)
            
            if match:
                ingredients_str = ocr_text[match.end():].strip(': \n')
            else:
                ingredients_str = ocr_text

            all_ingredients = [
                ing.strip() 
                for ing in re.split(r'[,/\n]', ingredients_str) 
                if ing.strip() and len(ing.strip()) > 1
            ]
            return all_ingredients
        except Exception:
            return []

    def analyze_from_product_name(self, product_name: str) -> Optional[Dict[str, Any]]:
        """
        ì œí’ˆëª…ìœ¼ë¡œ ì§ì ‘ ê²€ìƒ‰í•˜ì—¬ ë¶„ì„í•©ë‹ˆë‹¤. (ì±„íŒ… UIì˜ 'ê²€ìƒ‰' ë²„íŠ¼ìš©)
        """
        # ì§ì ‘ ê²€ìƒ‰ì€ FTSë¥¼ ìš°ì„  ì‚¬ìš©
        product_data = self._search_product_by_name(product_name, use_fts=True)
        
        if not product_data:
            return None
        
        caution_ingredients = self._query_caution_ingredients(product_data.get('ingredients', []))
        
        return {
            'source': 'database',
            'product_name': product_data.get('product_name'),
            'brand': product_data.get('brand'),
            'price_krw': product_data.get('price_krw'),
            'capacity': product_data.get('capacity'),
            'image_url': product_data.get('image_url'),
            'ingredients': product_data.get('ingredients', []),
            'caution_ingredients': caution_ingredients,
            'ocr_text': None,
            'validation': {'is_valid': True, 'has_text': True, 'match_count': 0}
        }
    
    def _search_product_by_name(self, product_name: str, use_fts: bool = True) -> Optional[Dict[str, Any]]:
        """[ìˆ˜ì •] ì œí’ˆëª…ìœ¼ë¡œ DBë¥¼ ê²€ìƒ‰ (FTS ë˜ëŠ” LIKE)"""
        try:
            with self.engine.connect() as conn:
                result = None
                
                # 1. FTS ê²€ìƒ‰ (ì •í™•ë„ ë†’ìŒ)
                if use_fts:
                    query_fts = text("""
                        SELECT 
                            product_name, brand, image_url, price_krw, capacity, ingredients,
                            MATCH(product_name) AGAINST(:name IN NATURAL LANGUAGE MODE) as relevance_score
                        FROM product_data 
                        WHERE MATCH(product_name) AGAINST(:name IN NATURAL LANGUAGE MODE)
                        ORDER BY relevance_score DESC
                        LIMIT 1
                    """)
                    result_fts = conn.execute(query_fts, {"name": product_name}).fetchone()
                    if result_fts and result_fts[6] > 0.5: # FTS ì ìˆ˜ 0.5 ì´ìƒë§Œ ì‹ ë¢°
                        result = result_fts

                # 2. FTSê°€ ì‹¤íŒ¨í–ˆê±°ë‚˜(None) ì‚¬ìš© ì•ˆ í•¨(False) ê²½ìš°, LIKE ê²€ìƒ‰ (Fallback)
                if not result:
                    query_like = text("""
                        SELECT product_name, brand, image_url, price_krw, capacity, ingredients
                        FROM product_data
                        WHERE product_name LIKE :name
                        LIMIT 1
                    """)
                    result_like = conn.execute(query_like, {"name": f"%{product_name}%"}).fetchone()
                    result = result_like

                # ìµœì¢… ê²°ê³¼ ì²˜ë¦¬
                if result:
                    return {
                        'product_name': result[0],
                        'brand': result[1],
                        'image_url': result[2],
                        'price_krw': result[3],
                        'capacity': result[4],
                        'ingredients': result[5].split(',') if result[5] else []
                    }
                return None
        except Exception as e:
            print(f"DB ê²€ìƒ‰ ì˜¤ë¥˜ (_search_product_by_name): {e}")
            return None
    
    def _fuzzy_search_product(self, ocr_text: str) -> Optional[Dict[str, Any]]:
        """[ìˆ˜ì •] OCR í…ìŠ¤íŠ¸ì—ì„œ ì œí’ˆì„ FTSë¡œ ì°¾ìŠµë‹ˆë‹¤. (OCR_streamlit.py ë°©ì‹)"""
        try:
            with self.engine.connect() as conn:
                query = text("""
                    SELECT 
                        product_name, brand, image_url, price_krw, capacity, ingredients,
                        MATCH(product_name) AGAINST(:text IN NATURAL LANGUAGE MODE) as relevance_score
                    FROM product_data
                    WHERE MATCH(product_name) AGAINST(:text IN NATURAL LANGUAGE MODE)
                    ORDER BY relevance_score DESC
                    LIMIT 1
                """)
                
                result = conn.execute(query, {"text": ocr_text}).fetchone()
                
                if result and result[6] > 0.5: # ê´€ë ¨ë„ 0.5 ì´ìƒ
                    product_name = result[0]
                    product_words = [word for word in product_name.split() if len(word) > 1]
                    ocr_lower = ocr_text.lower()
                    
                    match_count = sum(1 for word in product_words if word.lower() in ocr_lower)
                    match_ratio = match_count / len(product_words) if product_words else 0
                    
                    if match_ratio >= 0.3: # ì œí’ˆëª… ë‹¨ì–´ 30% ì´ìƒ ì¼ì¹˜
                        return {
                            'product_name': result[0],
                            'brand': result[1],
                            'image_url': result[2],
                            'price_krw': result[3],
                            'capacity': result[4],
                            'ingredients': result[5].split(',') if result[5] else []
                        }
                
                return None
        except Exception as e:
            print(f"í¼ì§€ ê²€ìƒ‰ ì˜¤ë¥˜ (_fuzzy_search_product): {e}")
            return None
    
    def _query_caution_ingredients(self, ingredients: List[str]) -> Dict[str, List[Dict[str, Any]]]:
        """
        [ìˆ˜ì •]
        1. ML í…Œì´ë¸”ëª…: ML_caution_ingredients
        2. ML í…Œì´ë¸” ì»¬ëŸ¼: korean_name, caution_grade, description
        """
        if not ingredients:
            return {'official': [], 'ml_predicted': []}
        
        try:
            with self.engine.connect() as conn:
                # 1. íŒŒë¼ë¯¸í„° ì¤€ë¹„
                placeholders = ','.join([':ing' + str(i) for i in range(len(ingredients))])
                params = {f'ing{i}': ing.strip() for i, ing in enumerate(ingredients)}
                
                # 2. ê³µì‹ ì£¼ì˜ ì„±ë¶„ ì¡°íšŒ
                official_query = text(f"""
                    SELECT 
                        korean_name,
                        caution_grade,
                        description
                    FROM caution_ingredients
                    WHERE korean_name IN ({placeholders})
                """)
                
                official_results = conn.execute(official_query, params).fetchall()
                official_list = [
                    {
                        'korean_name': row[0],
                        'caution_grade': row[1],
                        'description': row[2]
                    }
                    for row in official_results
                ]
                
                # 3. ML ì˜ˆì¸¡ ì£¼ì˜ ì„±ë¶„ ì¡°íšŒ (ê³µì‹ì— ì—†ëŠ” ê²ƒë§Œ)
                official_names = {item['korean_name'] for item in official_list}
                remaining_ingredients = [ing for ing in ingredients if ing not in official_names]
                
                ml_list = []
                if remaining_ingredients:
                    # 4. ë‚¨ì€ ì„±ë¶„ìš© íŒŒë¼ë¯¸í„° ì¤€ë¹„
                    ml_placeholders = ','.join([':rem' + str(i) for i in range(len(remaining_ingredients))])
                    ml_params = {f'rem{i}': ing.strip() for i, ing in enumerate(remaining_ingredients)}

                    # [ìˆ˜ì •] í…Œì´ë¸”ëª…ê³¼ ì»¬ëŸ¼ëª… ë³€ê²½
                    ml_query = text(f"""
                        SELECT 
                            korean_name,
                            caution_grade,
                            description
                        FROM ML_caution_ingredients 
                        WHERE korean_name IN ({ml_placeholders})
                    """)
                    
                    try:
                        ml_results = conn.execute(ml_query, ml_params).fetchall()
                        ml_list = [
                            {
                                'korean_name': row[0],
                                'caution_grade': row[1],
                                'description': row[2]
                            }
                            for row in ml_results
                        ]
                    except Exception as e:
                        print(f"ML ì£¼ì˜ ì„±ë¶„ ì¡°íšŒ ì˜¤ë¥˜ (ML_caution_ingredients): {e}")
                        ml_list = [] # í…Œì´ë¸”ì´ ì—†ê±°ë‚˜ ì˜¤ë¥˜ ë°œìƒ ì‹œ ë¬´ì‹œ
                
                return {
                    'official': official_list,
                    'ml_predicted': ml_list
                }
        except Exception as e:
            print(f"ì£¼ì˜ ì„±ë¶„ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return {'official': [], 'ml_predicted': []}

# ============================================
# ë©”ì¸ ì²˜ë¦¬ í•¨ìˆ˜ (ìˆ˜ì • ì—†ìŒ)
# ============================================

def process_cosmetic_image(image_path: str) -> Dict[str, Any]:
    """
    í™”ì¥í’ˆ ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•˜ê³  ë¶„ì„ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    ocr_text = extract_text_from_image(image_path)
    
    if not ocr_text:
        return {
            'success': False,
            'error': 'OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨',
            'data': None
        }
    
    analyzer = CosmeticAnalyzer()
    result = analyzer.analyze_from_text(ocr_text)
    
    if result:
        return {
            'success': True,
            'error': None,
            'data': result
        }
    else:
        return {
            'success': False,
            'error': 'í™”ì¥í’ˆ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.',
            'data': None
        }

def search_product_by_name(product_name: str) -> Dict[str, Any]:
    """
    ì œí’ˆëª…ìœ¼ë¡œ ì§ì ‘ ê²€ìƒ‰í•©ë‹ˆë‹¤.
    """
    analyzer = CosmeticAnalyzer()
    result = analyzer.analyze_from_product_name(product_name)
    
    if result:
        return {
            'success': True,
            'error': None,
            'data': result
        }
    else:
        return {
            'success': False,
            'error': 'ì œí’ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.',
            'data': None
        }

def format_analysis_for_chat(analysis_result: Dict[str, Any]) -> Dict[str, Any]:
    """
    [ìˆ˜ì •] ML ì˜ˆì¸¡ ì„±ë¶„ í¬ë§¤íŒ… ë¡œì§ ìˆ˜ì •
    """
    if not analysis_result.get('success'):
        return {
            'text': f"âŒ {analysis_result.get('error', 'ë¶„ì„ ì‹¤íŒ¨')}",
            'image_url': None
        }
    
    data = analysis_result.get('data', {})
    
    output = []
    output.append("## ğŸ§´ í™”ì¥í’ˆ ë¶„ì„ ê²°ê³¼\n")
    
    # ì œí’ˆ ì •ë³´
    if data.get('source') == 'database':
        output.append(f"**ì œí’ˆëª…**: {data.get('product_name', 'N/A')}")
        if data.get('brand'):
            output.append(f"**ë¸Œëœë“œ**: {data['brand']}")
        if data.get('price_krw'):
            output.append(f"**ê°€ê²©**: {data['price_krw']:,}ì›")
        if data.get('capacity'):
            output.append(f"**ìš©ëŸ‰**: {data['capacity']}")
    elif data.get('source') == 'ocr_direct_analysis':
        output.append("â„¹ï¸ DBì—ì„œ ì œí’ˆì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        output.append(f"{data.get('error', 'OCR í…ìŠ¤íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì„±ë¶„ë§Œ ë¶„ì„í•©ë‹ˆë‹¤.')}\n")

    output.append("")
    
    # ì£¼ì˜ ì„±ë¶„
    caution = data.get('caution_ingredients', {})
    official = caution.get('official', [])
    ml_predicted = caution.get('ml_predicted', [])
    
    # 1ì°¨: ê³µì‹ ì£¼ì˜ ì„±ë¶„
    if official:
        output.append(f"### âš ï¸ ì£¼ì˜ ì„±ë¶„ ({len(official)}ê°œ)")
        output.append("\n**ê³µì‹ ì£¼ì˜ ì„±ë¶„:**")
        for ing in official:
            grade = ing.get('caution_grade', 'N/A')
            name = ing.get('korean_name', 'N/A')
            desc = ing.get('description', '')
            output.append(f"- **{name}** (ë“±ê¸‰: {grade})")
            if desc:
                output.append(f"  {desc}")
        output.append("")
    
    # ê³µì‹/ML ëª¨ë‘ ì—†ì„ ë•Œ
    if not official and not ml_predicted:
        output.append("### âœ… ì£¼ì˜ ì„±ë¶„ ì—†ìŒ")
        output.append("ì´ ì œí’ˆì—ëŠ” ê³µì‹ ë“±ë¡ëœ ì£¼ì˜ ì„±ë¶„ì´ë‚˜ AI ì˜ˆì¸¡ ìœ í•´ ì„±ë¶„ì´ ì—†ìŠµë‹ˆë‹¤.\n")
    # ê³µì‹ì€ ì—†ì§€ë§Œ MLì€ ìˆì„ ë•Œ
    elif not official and ml_predicted:
        output.append("### âœ… ê³µì‹ ì£¼ì˜ ì„±ë¶„ ì—†ìŒ")
        output.append("ì´ ì œí’ˆì—ëŠ” ê³µì‹ ë“±ë¡ëœ ì£¼ì˜ ì„±ë¶„ì´ ì—†ìŠµë‹ˆë‹¤.\n")
    
    # 2ì°¨: ML ì˜ˆì¸¡ ì£¼ì˜ ì„±ë¶„ (ì¶”ê°€ ì •ë³´)
    if ml_predicted:
        output.append(f"### ğŸ“Š ì¶”ê°€ë¡œ ì•Œì•„ë‘ë©´ ì¢‹ì„ ì„±ë¶„ (AI ì˜ˆì¸¡) ({len(ml_predicted)}ê°œ)")
        output.append("*ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ë¡œ ì˜ˆì¸¡ëœ ë¹„ì•ˆì „ ì„±ë¶„ì…ë‹ˆë‹¤.*\n")
        for ing in ml_predicted:
            name = ing.get('korean_name', 'N/A')
            # [ìˆ˜ì •] ML_caution_ingredients ìŠ¤í‚¤ë§ˆ(caution_grade, description)ë¥¼ ë”°ë¦„
            grade = ing.get('caution_grade', 'N/A')
            desc = ing.get('description', '')
            output.append(f"- **{name}** (ì˜ˆì¸¡ ë“±ê¸‰: {grade})")
            if desc:
                output.append(f"  {desc}")
    
    return {
        'text': "\n".join(output),
        'image_url': data.get('image_url')
    }