# pages/2_Chat.py
# ============================================
# í™”ì¥í’ˆ ì¶”ì²œ ì±—ë´‡ í˜ì´ì§€ (OCR í†µí•© ë²„ì „)
# [ìˆ˜ì •] UI/UX ê°œì„  (ì±„íŒ… ì´ˆê¸°í™” ë²„íŠ¼ ìœ„ì¹˜ ë³€ê²½)
# ============================================

import streamlit as st
import json
import tempfile
import os
from pathlib import Path
from openai import OpenAI
from dotenv import load_dotenv

# ============================================
# UI ëª¨ë“ˆ import
# ============================================
import sys
sys.path.append(str(Path(__file__).parent.parent))

try:
    from aller.ui import require_login_redirect, render_app_sidebar
except ImportError:
    st.error("aller/ui.py íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. aller í´ë”ì— ui.pyê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
    st.stop()

# ============================================
# OCR ëª¨ë“ˆ import
# ============================================
try:
    from utils.OCR import process_cosmetic_image, search_product_by_name, format_analysis_for_chat
except ImportError:
    st.error("utils/OCR.py íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. utils í´ë”ì— OCR.pyê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
    st.stop()

# ============================================
# ë¡œê·¸ì¸ ì²´í¬ ë° ì»¤ìŠ¤í…€ ì‚¬ì´ë“œë°” ë Œë”ë§
# ============================================
require_login_redirect()
render_app_sidebar()

# ============================================
# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ ë° OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
# ============================================
load_dotenv()
client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# ============================================
# í˜ì´ì§€ ì„¤ì •
# ============================================
st.title("ğŸ’¬ í™”ì¥í’ˆ ì¶”ì²œ ì±—ë´‡")
st.caption("í™”ì¥í’ˆì— ëŒ€í•´ ë¬´ì—‡ì´ë“  ë¬¼ì–´ë³´ì„¸ìš”! ğŸ“ ë²„íŠ¼ìœ¼ë¡œ ì œí’ˆì„ ë¶„ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

# ============================================
# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
# ============================================
if "messages" not in st.session_state:
    st.session_state.messages = [
        {
            "role": "system",
            "content": """ë‹¹ì‹ ì€ ì „ë¬¸ í™”ì¥í’ˆ ìƒë‹´ì‚¬ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ í”¼ë¶€ ê³ ë¯¼ì„ ë“£ê³  ì í•©í•œ í™”ì¥í’ˆì„ ì¶”ì²œí•´ì£¼ì„¸ìš”.
            
- ì‚¬ìš©ìê°€ OCRë¡œ ë¶„ì„í•œ ì œí’ˆ ì •ë³´ê°€ ìˆë‹¤ë©´, ê·¸ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìƒì„¸í•œ ì¡°ì–¸ì„ ì œê³µí•˜ì„¸ìš”.
- ì„±ë¶„ì— ëŒ€í•œ ì„¤ëª…ì´ í•„ìš”í•˜ë©´ ìì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.
- ì£¼ì˜ ì„±ë¶„ì´ ìˆë‹¤ë©´ ì™œ ì£¼ì˜í•´ì•¼ í•˜ëŠ”ì§€ ì„¤ëª…í•˜ê³  ëŒ€ì•ˆì„ ì œì‹œí•˜ì„¸ìš”.
- ì¹œê·¼í•˜ê³  ì „ë¬¸ì ì¸ í†¤ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”."""
        }
    ]

if "ocr_context" not in st.session_state:
    st.session_state.ocr_context = []

# ============================================
# ì±„íŒ… ê¸°ë¡ í‘œì‹œ
# ============================================
for message in st.session_state.messages:
    if message["role"] != "system":
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
            if "image_url" in message and message["image_url"]:
                st.image(message["image_url"], width=300)

# ============================================
# [ìˆ˜ì •] ì²¨ë¶€/ê²€ìƒ‰ Popover ë° ì±„íŒ… ì´ˆê¸°í™” ë²„íŠ¼
# ============================================

# [ìˆ˜ì •] chat_input ë°”ë¡œ ìœ„ì— ë‘ ê°œì˜ ì—´ ìƒì„±
col1, col2, col_rest = st.columns([1, 1, 8]) # ë²„íŠ¼ë“¤ì„ ì™¼ìª½ì— ì‘ê²Œ ë°°ì¹˜

with col1:
    # Popover ì»¨íŠ¸ë¡¤ëŸ¬
    with st.popover("ğŸ“ì²¨ë¶€/ê²€ìƒ‰", help="ì²¨ë¶€/ê²€ìƒ‰", use_container_width=False):
        st.markdown("##### ğŸ“¸ ì‚¬ì§„ìœ¼ë¡œ ë¶„ì„")
        uploaded_file = st.file_uploader(
            "í™”ì¥í’ˆ ì‚¬ì§„ì„ ì—…ë¡œë“œí•˜ì„¸ìš”",
            type=["jpg", "jpeg", "png"],
            key="chat_image_uploader",
            label_visibility="collapsed"
        )
        
        st.divider()
        
        st.markdown("##### ğŸ” ì œí’ˆëª…ìœ¼ë¡œ ê²€ìƒ‰")
        with st.form("product_search_form"):
            product_name = st.text_input(
                "ì œí’ˆëª… ì…ë ¥",
                placeholder="ì˜ˆ: ì¼ë¦¬ìœ¤ ì„¸ë¼ë§ˆì´ë“œ ì•„í†  ë¡œì…˜",
                key="product_search_input",
                label_visibility="collapsed"
            )
            search_submitted = st.form_submit_button("ê²€ìƒ‰", use_container_width=True)

with col2:
    # [ì‹ ê·œ] ì±„íŒ… ê¸°ë¡ ì§€ìš°ê¸° ë²„íŠ¼
    if st.button("ğŸ—‘ï¸ê¸°ë¡ ì§€ìš°ê¸°", help="ì±„íŒ… ê¸°ë¡ ì§€ìš°ê¸°", use_container_width=True):
         st.session_state.messages = [st.session_state.messages[0]]
         st.session_state.ocr_context = []
         st.rerun()

# [ìˆ˜ì •] Popover ë¡œì§ (ìœ„ì ¯ ì •ì˜ ì´í›„ì— ìœ„ì¹˜í•´ì•¼ í•¨)
if search_submitted and product_name:
    with st.spinner("ì œí’ˆì„ ê²€ìƒ‰í•˜ëŠ” ì¤‘..."):
        try:
            result = search_product_by_name(product_name)
            
            if result.get('success'):
                data = result.get('data', {})
                ocr_json = {
                    "product_name": data.get('product_name'),
                    "brand": data.get('brand'),
                    "price_krw": data.get('price_krw'),
                    "capacity": data.get('capacity'),
                    "image_url": data.get('image_url'),
                    "ingredients": data.get('ingredients', []),
                    "caution_ingredients": data.get('caution_ingredients', {}),
                    "source": "database_search"
                }
                st.session_state.ocr_context.append(ocr_json)
                formatted_result = format_analysis_for_chat(result)
                st.session_state.messages.append({
                    "role": "assistant",
                    "content": formatted_result['text'],
                    "image_url": formatted_result['image_url']
                })
                st.success("âœ… ê²€ìƒ‰ ì™„ë£Œ!")
                st.rerun()
            else:
                st.error(f"âŒ {result.get('error', 'ì œí’ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')}")
        except Exception as e:
            st.error(f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

if uploaded_file is not None:
    if 'last_uploaded_file' not in st.session_state or st.session_state.last_uploaded_file != uploaded_file.name:
        st.session_state.last_uploaded_file = uploaded_file.name
        with st.spinner("ğŸ“¸ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ëŠ” ì¤‘..."):
            with tempfile.NamedTemporaryFile(delete=False, suffix=".jpg") as tmp_file:
                tmp_file.write(uploaded_file.getvalue())
                tmp_path = tmp_file.name
            try:
                result = process_cosmetic_image(tmp_path)
                if result.get('success'):
                    data = result.get('data', {})
                    ocr_json = {
                        "product_name": data.get('product_name'),
                        "brand": data.get('brand'),
                        "price_krw": data.get('price_krw'),
                        "capacity": data.get('capacity'),
                        "image_url": data.get('image_url'),
                        "ingredients": data.get('ingredients', []),
                        "caution_ingredients": data.get('caution_ingredients', {}),
                        "source": data.get('source')
                    }
                    st.session_state.ocr_context.append(ocr_json)
                    formatted_result = format_analysis_for_chat(result)
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": formatted_result['text'],
                        "image_url": formatted_result['image_url']
                    })
                    st.success("âœ… ë¶„ì„ ì™„ë£Œ!")
                    st.rerun()
                else:
                    st.error(f"âŒ {result.get('error', 'ë¶„ì„ ì‹¤íŒ¨')}")
            except Exception as e:
                st.error(f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            finally:
                if os.path.exists(tmp_path):
                    os.unlink(tmp_path)

# ============================================
# ì±„íŒ… ì…ë ¥ ë° GPT ì‘ë‹µ ì²˜ë¦¬
# ============================================
if prompt := st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”..."):
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    st.session_state.messages.append({"role": "user", "content": prompt})
    
    with st.chat_message("user"):
        st.markdown(prompt)
    
    # GPT ì‘ë‹µ ìƒì„±
    with st.chat_message("assistant"):
        message_placeholder = st.empty()
        
        # OCR ì»¨í…ìŠ¤íŠ¸ê°€ ìˆë‹¤ë©´ ì‹œìŠ¤í…œ ë©”ì‹œì§€ì— ì¶”ê°€
        messages_to_send = st.session_state.messages.copy()
        
        if st.session_state.ocr_context:
            ocr_context_text = "\n\n### ë¶„ì„ëœ ì œí’ˆ ì •ë³´:\n"
            for idx, ocr_data in enumerate(st.session_state.ocr_context, 1):
                ocr_context_text += f"\n**ì œí’ˆ {idx}:**\n"
                ocr_context_text += f"- ì œí’ˆëª…: {ocr_data.get('product_name', 'N/A')}\n"
                ocr_context_text += f"- ë¸Œëœë“œ: {ocr_data.get('brand', 'N/A')}\n"
                
                caution = ocr_data.get('caution_ingredients', {})
                official_ings = [ing['korean_name'] for ing in caution.get('official', [])]
                ml_ings = [ing['korean_name'] for ing in caution.get('ml_predicted', [])]
                
                if official_ings:
                    ocr_context_text += f"- ê³µì‹ ì£¼ì˜ ì„±ë¶„: {', '.join(official_ings)}\n"
                if ml_ings:
                    ocr_context_text += f"- AI ì˜ˆì¸¡ ìœ í•´ ì„±ë¶„: {', '.join(ml_ings)}\n"
            
            messages_to_send[0] = {
                "role": "system",
                "content": messages_to_send[0]["content"] + ocr_context_text
            }
        
        try:
            stream = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=messages_to_send,
                stream=True,
                temperature=0.7,
                max_tokens=2000
            )
            
            full_response = ""
            for chunk in stream:
                if chunk.choices[0].delta.content is not None:
                    full_response += chunk.choices[0].delta.content
                    message_placeholder.markdown(full_response + "â–Œ")
            
            message_placeholder.markdown(full_response)
            
            st.session_state.messages.append({
                "role": "assistant",
                "content": full_response
            })
        
        except Exception as e:
            st.error(f"âŒ GPT ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            message_placeholder.markdown("ì£„ì†¡í•©ë‹ˆë‹¤. ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")

# ============================================
# [ì‚­ì œ] ì±„íŒ… ê¸°ë¡ ì´ˆê¸°í™” ë²„íŠ¼ (í•˜ë‹¨)
# ============================================
# st.divider()
# col1, col2, col3 = st.columns([1, 1, 1])
# ... (í•˜ë‹¨ ë²„íŠ¼ ë¡œì§ ì „ì²´ ì‚­ì œ) ...